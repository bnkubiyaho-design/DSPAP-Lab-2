{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4691ec79",
   "metadata": {},
   "source": [
    "# Python Data Analysis Basics Lab ‚Äî Open Food Facts (France)\n",
    "\n",
    "**Objective.** Demonstrate fluency with **NumPy/Pandas**, descriptive analysis, and basic **Matplotlib** plots. \n",
    "An optional **PCA** challenge closes the TP.\n",
    "\n",
    "If you don't manage to end it in class, you can continue it at home.\n",
    "Send the complete TP to angelo.furno@entpe.fr. \n",
    "Add your name to the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e539b",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset.** We will use a reduced France-focused subset of the Open Food Facts dataset (OFF) hosted at:  \n",
    "`https://people.licit-lyon.eu/furno/courses/2025/class_01/processed_openfoodfacts_fr.csv`  \n",
    "\n",
    "Once you have completed the download, add the file in a local path: `data/processed_openfoodfacts_fr.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9f129",
   "metadata": {},
   "source": [
    "\n",
    "**Skills you will practice**\n",
    "- Pandas essentials: Series/DataFrame, indexing/slicing, dtypes, creating columns, missing values, groupby/aggregation.\n",
    "- Descriptive analytics: distributions, crosstabs, category/brand summaries.\n",
    "- Plotting with Matplotlib: histogram, bar, box, scatter.\n",
    "- Optional PCA: scaling, explained variance, **correlation circle (PC1‚ÄìPC2)**, interpreting loadings.\n",
    "\n",
    "**Gamified scoring.** Each task has XP. At the end, your **grade /20** is computed from XP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce10aea",
   "metadata": {},
   "source": [
    "## XP & Grading \n",
    "- Part A ‚Äî Pandas Fundamentals (max **40 XP**)\n",
    "- Part B ‚Äî Descriptive Plots & Interpretation (max **25 XP**)\n",
    "- Part C ‚Äî Brands & Categories Mini-Projects (max **15 XP**)\n",
    "- Part D ‚Äî PCA (optional, max **20 XP**)\n",
    "\n",
    "**Target = 80 XP** ‚Üí Grade = `min(20, round(20 * XP / 80, 1))`.  \n",
    "Extra XP beyond 80 adds buffer, but max grade is **20/20**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT CHANGE THIS CELL\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "except Exception:\n",
    "    print(\"Scikit-learn not found. Please install it with `pip install scikit-learn`.\")\n",
    "    PCA = None\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "DATA_URL = \"https://people.licit-lyon.eu/furno/courses/2025/processed_openfoodfacts_fr.csv\"\n",
    "LOCAL_FALLBACK = \"data/processed_openfoodfacts_fr.csv\"\n",
    "\n",
    "# --- XP utilities (lightweight) ---\n",
    "XP = 0\n",
    "HINTS = 4       # number of hint tokens\n",
    "PENALTY = 1     # XP penalty per hint\n",
    "\n",
    "def award(points, why=\"\"):\n",
    "    global XP\n",
    "    XP += int(points)\n",
    "    print(f\"+{points} XP ‚Äî {why} (total={XP})\")\n",
    "\n",
    "def grade_summary():\n",
    "    grade = min(20, round(20 * XP / 80, 1))\n",
    "    print(f\"Final XP={XP} ‚Üí Grade={grade}/20\")\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116b315",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "This lab uses a reduced subset of the **Open Food Facts (France)** database.\n",
    "\n",
    "## What is the Open Food Facts dataset?\n",
    "\n",
    "The **Open Food Facts (OFF) dataset** is a large, open, collaborative database of packaged food products, available online: `https://fr.openfoodfacts.org/decouvrir`.  \n",
    "It is sometimes called the *‚ÄúWikipedia of food‚Äù*, since anyone can contribute information by scanning barcodes, uploading ingredients lists, or adding nutrition facts.\n",
    "\n",
    "**Why is it interesting for us?**\n",
    "- It is **real, messy data**: not all fields are complete or consistent.\n",
    "- It covers a **broad variety of products** consumed daily in France and worldwide.\n",
    "- It allows analysis of **nutrition, brands, categories, and health scores**.\n",
    "- It is open data (licensed under ODbL), widely used by researchers, NGOs, and consumer apps.\n",
    "\n",
    "In this lab we use a **France-focused subset**, with selected columns on metadata, nutrients, and scores.  \n",
    "Your challenge: **explore, clean, and visualize** this data to uncover insights about the food we eat!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9a310",
   "metadata": {},
   "source": [
    "Key columns are:\n",
    "\n",
    "- **Metadata**\n",
    "  - `code`: unique product identifier (barcode)\n",
    "  - `product_name`: product‚Äôs name\n",
    "  - `brands`: comma-separated list of brands\n",
    "  - `categories`: comma-separated categories (hierarchical)\n",
    "  - `pnns_groups_1`: high-level food group (e.g., Beverages, Milk and dairy products)\n",
    "  - `pnns_groups_2`: finer-grained food group (e.g., Fruit juices, Sweetened beverages)\n",
    "  - `countries_tags`: tags for countries where product is sold\n",
    "\n",
    "- **Nutrients per 100g**\n",
    "  - `energy-kcal_100g`: energy content (kcal per 100 g)\n",
    "  - `sugars_100g`: sugars (g per 100 g)\n",
    "  - `fat_100g`: total fat (g per 100 g)\n",
    "  - `saturated-fat_100g`: saturated fat (g per 100 g)\n",
    "  - `salt_100g`: salt (g per 100 g)\n",
    "  - `fiber_100g`: fiber (g per 100 g)\n",
    "  - `proteins_100g`: proteins (g per 100 g)\n",
    "\n",
    "- **Labels and Scores**\n",
    "  - `nutriscore_grade`: grade (a‚Äìe) of the Nutri-Score label (a=best, e=worst)\n",
    "  - `nutriscore_score`: numeric score used to derive the Nutri-Score grade\n",
    "  - `nova_group`: NOVA group classification of food processing level (1‚Äì4)\n",
    "  - `environmental_score_grade`: eco-score label (a‚Äìe)\n",
    "\n",
    "- **Popularity (proxy)**\n",
    "  - `unique_scans_n`: approximate count of how many times a product has been scanned by users (proxy for popularity)\n",
    "\n",
    "This dataset is **heterogeneous**: not every product has complete nutrition data, and some fields can be missing or noisy.  \n",
    "The exercises will guide you through inspecting, cleaning, transforming, and visualizing this data.\n",
    "\n",
    "\n",
    "Your mission is to **describe** the data: inspect, clean, transform, aggregate, visualize, and **explain** what you see.\n",
    "\n",
    "**Note: To reduce the size of the original dataset, some columns have already been removed!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651aeac",
   "metadata": {},
   "source": [
    "# Part A ‚Äî Pandas Fundamentals (40 XP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2913352",
   "metadata": {},
   "source": [
    "## A1. Load & Inspect (6 XP)\n",
    "\n",
    "In this exercise you load the dataset, inspect its structure, and quantify missingness.\n",
    "\n",
    "**Tasks**\n",
    "### A1.1 Loading (1 XP)\n",
    "Load the CSV into a DataFrame `df`. \n",
    "\n",
    "Hint: Use the `pd.read_csv()` function. \n",
    "   - Docs: [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a71e41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.1 ‚Äî Load the dataset\n",
    "# Use the local copy bundled with this TP.\n",
    "csv_path = \"processed_openfoodfacts_fr.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "# Keep a copy of the original for reference if needed\n",
    "df_raw = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb192ae",
   "metadata": {},
   "source": [
    "### A1.2 Preview and Shape (1 XP)\n",
    "Show the first 5 rows with `df.head()` and print the shape `(rows, cols)`.\n",
    "   - Docs: [DataFrame.head](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html), [DataFrame.shape](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b205a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.2 ‚Äî Preview and shape\n",
    "print(\"Shape (rows, cols):\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecdbdbf",
   "metadata": {},
   "source": [
    "### A1.3 Data info (1 XP)\n",
    "Display column dtypes and run `df.info(memory_usage=\"deep\")` to see non-null counts and memory usage.\n",
    "   - Docs: [DataFrame.dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html), [DataFrame.info](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f69da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.3 ‚Äî Data info\n",
    "print(\"Dtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nInfo (deep memory usage):\")\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6b09b",
   "metadata": {},
   "source": [
    "### A1.4 Exploring Categorical Variables (1 XP)\n",
    "Explore the values of **categorical variables**, such as:\n",
    "   - `pnns_groups_1` (main food groups),\n",
    "   - `nutriscore_grade` (nutrition label a‚Äìe),\n",
    "   - `brands` (most frequent brands).  \n",
    "\n",
    "   Hint: use `unique`() and `.value_counts()` to display the most frequent categories, and check how diverse they are.  \n",
    "   - Docs: [Series.value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0fcdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.4 ‚Äî Explore categorical variables\n",
    "# View distributions of selected categorical columns\n",
    "cat_cols = [\"pnns_groups_1\", \"nutriscore_grade\", \"brands\"]\n",
    "for c in cat_cols:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\nValue counts for {c}:\")\n",
    "        print(df[c].value_counts(dropna=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4203023",
   "metadata": {},
   "source": [
    "### A1.5. Missing Values (2 XP)\n",
    "Compute the **missingness ratio** per column, sort it descending, and show the **top 5**.\n",
    "   - Docs: [DataFrame.isna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html), [Series.sort_values](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb73bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.5 ‚Äî Missing values\n",
    "missing_ratio = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"Top missingness ratios:\")\n",
    "missing_ratio.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3a203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+6 XP ‚Äî A1: Completed data loading and basic inspection (total=6)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2742836",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## A2. Selecting, Filtering, Slicing (8 XP)\n",
    "\n",
    "Build a focused view of the data to practice column selection, row filtering, and slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f5a64",
   "metadata": {},
   "source": [
    "### A2.1 ‚Äî Select a column subset into `df_sub` (1 XP)\n",
    "\n",
    "Create `df_sub` with columns:  \n",
    "`product_name, brands, pnns_groups_1, sugars_100g, fat_100g, salt_100g, proteins_100g, nutriscore_grade`.\n",
    "\n",
    "**Hint:** Use `df[cols].copy()` when you plan to transform this subset.\n",
    "\n",
    "We‚Äôll build a focused subset for this task.  \n",
    "üí° When creating a working subset you intend to modify, always use `.copy()` to avoid `SettingWithCopyWarning`. This is not necessary if you just need to explore the dataset without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0bad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.1 ‚Äî Select a column subset into df_sub\n",
    "cols = [\n",
    "    \"product_name\",\"brands\",\"pnns_groups_1\",\n",
    "    \"sugars_100g\",\"fat_100g\",\"salt_100g\",\"proteins_100g\",\n",
    "    \"nutriscore_grade\"\n",
    "]\n",
    "df_sub = df[cols].copy()\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383873ec",
   "metadata": {},
   "source": [
    "### A2.2 ‚Äî Filter by categories with a boolean mask (1 XP)\n",
    "\n",
    "Keep only rows where `pnns_groups_1` ‚àà {Beverages, Sugary snacks, Milk and dairy products}.\n",
    "\n",
    "**Hint:** Build a mask with `.isin(...)`, then use `.loc[mask, :]`.  \n",
    "Avoid chained indexing like `df_sub[df_sub[...] ...]` if you will modify later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee011a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.2 ‚Äî Filter by categories with a boolean mask\n",
    "keep_groups = {\"Beverages\", \"Sugary snacks\", \"Milk and dairy products\"}\n",
    "mask = df_sub[\"pnns_groups_1\"].isin(keep_groups)\n",
    "df_sub = df_sub.loc[mask].copy()\n",
    "df_sub[\"pnns_groups_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37cb75a",
   "metadata": {},
   "source": [
    "### A2.3 ‚Äî Positional slicing with `.iloc` (1 XP)\n",
    "\n",
    "Show rows **10:20** by **position** (0-based).  \n",
    "<br>Note: `.iloc[start:stop]` is **exclusive** of `stop`.\n",
    "\n",
    "- Docs: [DataFrame.iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3362a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.3 ‚Äî Positional slicing with .iloc\n",
    "# Show rows 10 to 19 and first 5 columns\n",
    "df_sub.iloc[10:20, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a0e43",
   "metadata": {},
   "source": [
    "### A2.4 ‚Äî Label-based selection with `.loc` (2 XP)\n",
    "\n",
    "Select **two rows by index label** using `.loc[[label1, label2]]`.\n",
    "\n",
    "1. First, demonstrate selection *by current index labels*.  \n",
    "2. Then, change the index to `product_name` (**without dropping** the column), and select two products by name.\n",
    "\n",
    "**Hints:**\n",
    "- `.loc` expects **labels** which can be integer or not depending on the index.\n",
    "- After `set_index(\"product_name\", drop=False)`, index labels become product names.  \n",
    "- If names are duplicated, `.loc[[\"Coca Cola\", \"Nutella\"]]` returns **multiple rows per name**.\n",
    "\n",
    "- Docs: [DataFrame.loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82eb9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.4 ‚Äî Label-based selection with .loc\n",
    "# Set product_name as the index (without dropping the column)\n",
    "df_sub = df_sub.set_index(\"product_name\", drop=False)\n",
    "\n",
    "# Select two specific products by name if they exist\n",
    "names = list(df_sub.index.dropna().unique())[:2]\n",
    "df_sub.loc[names, [\"brands\",\"pnns_groups_1\",\"sugars_100g\",\"proteins_100g\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfcb7a",
   "metadata": {},
   "source": [
    "### A2.5 ‚Äî Restoring the original RangeIndex (no XP)\n",
    "\n",
    "If you prefer position-based operations again, reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec71b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.5 ‚Äî Reset index back to RangeIndex\n",
    "df_sub = df_sub.reset_index(drop=True)\n",
    "df_sub.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e9679",
   "metadata": {},
   "source": [
    "### A2.6 ‚Äî A bit of thinking here (1 XP)\n",
    "**`.iloc` vs `.loc`**  \n",
    "- `.iloc` is **position-based** (uses integer positions). Slices are **half-open**: `start` included, `stop` excluded.  \n",
    "- `.loc` is **label-based** (uses index labels). When slicing by labels, both **endpoints are included**.  \n",
    "- `.loc` also accepts boolean masks and column label lists; `.iloc` only accepts integer positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186328b",
   "metadata": {},
   "source": [
    "### A2.7 ‚Äî Sorting (1 XP)\n",
    "Sort by `sugars_100g` descending and show top 10\n",
    "\n",
    "**Hint:** Use `.sort_values(..., ascending=False).head(10)`.  \n",
    "Prefer `.loc` if you want to select specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97042088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO A2.7\n",
    "# Fill in the code to perform the tasks described in the lab instructions.\n",
    "# Add as many cells as you need below this line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af4f89",
   "metadata": {},
   "source": [
    "### A2.8 ‚Äî Safer column selection after filtering when modifying a dataframe (1 XP)\n",
    "\n",
    "When you filter rows, prefer **boolean masks with `.loc`** over chained indexing.  \n",
    "\n",
    "- ‚úÖ Safe: \n",
    "        `mask = df[\"pnns_groups_1\"] == \"Beverages\"; df.loc[mask, \"sugars_100g\"] = 0`  \n",
    "- ‚ö†Ô∏è Risky: `df[df[\"pnns_groups_1\"] == \"Beverages\"][\"sugars_100g\"] = 0`  \n",
    "\n",
    "Why?  \n",
    "- `.loc` applies changes directly to the original DataFrame.  \n",
    "- Chained indexing can return a **temporary view**; updates may not propagate, and you may see a `SettingWithCopyWarning`.\n",
    "\n",
    "---\n",
    "\n",
    "**Minimal example: try this code, observe what happens and describe**\n",
    "\n",
    "```python\n",
    "\n",
    "    ex_df = pd.DataFrame({\n",
    "        \"pnns_groups_1\": [\"Beverages\", \"Snacks\", \"Beverages\"],\n",
    "        \"sugars_100g\": [10, 25, 35]\n",
    "    })\n",
    "    print(\"Original df:\\n\", ex_df, \"\\n\")\n",
    "\n",
    "    # --- Approach 1: Boolean mask with .loc (safe) ---\n",
    "    mask = ex_df[\"pnns_groups_1\"] == \"Beverages\"\n",
    "    ex_df.loc[mask, \"sugars_100g\"] = 0   # modify sugars for beverages\n",
    "    print(\"After .loc modification:\\n\", ex_df, \"\\n\")\n",
    "\n",
    "    # Reset for comparison\n",
    "    ex_df[\"sugars_100g\"] = [10, 25, 35]\n",
    "\n",
    "    # --- Approach 2: Chained filtering (risky) ---\n",
    "    ex_df[ex_df[\"pnns_groups_1\"] == \"Beverages\"][\"sugars_100g\"] = 0\n",
    "    print(\"After chained filtering modification:\\n\", ex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0eb29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO A2.8\n",
    "# Fill in the code to perform the tasks described in the lab instructions.\n",
    "# Add as many cells as you need below this line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc7b27",
   "metadata": {},
   "source": [
    "Write your conclusions below (bullet points are fine).\n",
    "- Use a boolean mask with .loc to modify filtered rows; it updates the original DataFrame reliably.\n",
    "- Avoid chained indexing like df[df[...]]['col'] = ...; it may write to a temporary copy (no effect) and often raises SettingWithCopyWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50158dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî A2: Completed data subsetting and sorting (total=14)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c1715",
   "metadata": {},
   "source": [
    "## A3. String operations & New columns (6 XP)\n",
    "\n",
    "We now go back to working on the full `df` (not on `df_sub`).\n",
    "\n",
    "The goal is to create new features from existing columns, using string methods and arithmetic operations.\n",
    "\n",
    "### A3.1. New columns (1 XP)\n",
    "Create a new column `sugar_to_protein` as the ratio `sugars_100g / (proteins_100g + 1e-6)`.  \n",
    "   - The `+1e-6` is to avoid division by zero when proteins = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb6fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3.1 ‚Äî New column: sugar_to_protein\n",
    "df[\"sugar_to_protein\"] = df[\"sugars_100g\"] / (df[\"proteins_100g\"] + 1e-6)\n",
    "df[[\"sugars_100g\",\"proteins_100g\",\"sugar_to_protein\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301727c4",
   "metadata": {},
   "source": [
    "### A3.2. Another one (2 XP)\n",
    "Create a boolean column `is_sweet` that is `True` if `sugars_100g > 15`.  \n",
    "   - Docs: [Comparison ops](https://pandas.pydata.org/docs/user_guide/dsintro.html#operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5601195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3.2 ‚Äî Boolean column is_sweet\n",
    "df[\"is_sweet\"] = df[\"sugars_100g\"] > 15\n",
    "df[\"is_sweet\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5d6eb",
   "metadata": {},
   "source": [
    "### A3.3. String manipulation + column creation (3XP)\n",
    "Explore the column `brands`. Some rows contain **multiple brands separated by commas** (e.g., `\"Nestl√©, Ricor√©\"`).  \n",
    "   - Find such rows explicitly using a string condition: `df[df[\"brands\"].str.contains(\",\", na=False)]`.  \n",
    "   - Display a few examples to see how the data looks.  \n",
    "   - Question: how could we extract only the *first* brand from such strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5500ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3.3 ‚Äî Explore multi-brand rows\n",
    "multi_brand_rows = df[df[\"brands\"].str.contains(\",\", na=False)]\n",
    "multi_brand_rows[[\"product_name\",\"brands\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fcd08",
   "metadata": {},
   "source": [
    "Create a new column `brand_main` as the **first brand** listed in `brands`, lowercased and stripped of spaces.  \n",
    "   - Hint: chain string operations like `str.split(\",\").str[0].str.strip().str.lower()`  \n",
    "   - Docs: [Series.str](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#string-handling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbe8740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3.3 ‚Äî Create brand_main (first brand, cleaned)\n",
    "df[\"brand_main\"] = (\n",
    "    df[\"brands\"]\n",
    "    .str.split(\",\")\n",
    "    .str[0]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "df[[\"brands\",\"brand_main\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee7e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+6 XP ‚Äî A3: Completed boolean masking and filtering (total=20)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120811c4",
   "metadata": {},
   "source": [
    "## A4. Types, Duplicates & Missing Values (8 XP)\n",
    "\n",
    "In this section you will:\n",
    "- remove duplicate products by name,\n",
    "- identify and handle missing values,\n",
    "- convert the Nutri-Score grade to an ordered categorical type,\n",
    "- perform simple imputations (no `groupby` yet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3421e84",
   "metadata": {},
   "source": [
    "### A4.1 ‚Äî Deduplicate by product name (4 XP)\n",
    "\n",
    "Many products share the same `product_name` (variants / re-entries).  \n",
    "We want to keep only the *most complete* row per product.\n",
    "\n",
    "1. **Normalize the product name**  \n",
    "   Hint: Use `.str.strip().str.lower()` on the `product_name` column to create a helper column, e.g. `name_norm`.\n",
    "\n",
    "2. **Build a completeness score**  \n",
    "   Compute the number of non-missing values **per row** over the *core nutrients*:  \n",
    "   `[\"sugars_100g\", \"fat_100g\", \"salt_100g\", \"proteins_100g\"]`  \n",
    "   and optionally: `\"energy-kcal_100g\"`, `\"fiber_100g\"`.  \n",
    "   Hint: Use `notna` and `sum` [DataFrame.notna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html), [DataFrame.sum](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\n",
    "\n",
    "3. **Sort rows by completeness**  \n",
    "   Place the most complete entries first.  \n",
    "   üìñ [DataFrame.sort_values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)\n",
    "\n",
    "4. **Drop duplicates**  \n",
    "   Keep only one row per normalized name using:  \n",
    "   ```python\n",
    "   df.drop_duplicates(subset=\"name_norm\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b499dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4.1 ‚Äî Deduplicate by product name\n",
    "# 1) Normalize product name\n",
    "df[\"name_norm\"] = df[\"product_name\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 2) Completeness score over core nutrients (and optional extras)\n",
    "core = [\"sugars_100g\",\"fat_100g\",\"salt_100g\",\"proteins_100g\"]\n",
    "optional = [c for c in [\"energy-kcal_100g\",\"fiber_100g\"] if c in df.columns]\n",
    "score_cols = core + optional\n",
    "df[\"_complete_n\"] = df[score_cols].notna().sum(axis=1)\n",
    "\n",
    "# 3) Sort by completeness (desc) then by non-missing count of all cols as tiebreaker\n",
    "df = df.sort_values(by=[\"name_norm\",\"_complete_n\"], ascending=[True, False])\n",
    "\n",
    "# 4) Drop duplicates keeping the most complete\n",
    "df = df.drop_duplicates(subset=\"name_norm\", keep=\"first\").copy()\n",
    "\n",
    "# Clean helper columns if desired (keep name_norm for later loc operations)\n",
    "df = df.drop(columns=[\"_complete_n\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf09021",
   "metadata": {},
   "source": [
    "### A4.2 ‚Äî Identify missingness (1 XP)\n",
    "\n",
    "We now check how complete our data is for the **4 core nutrients**:  \n",
    "`sugars_100g, fat_100g, salt_100g, proteins_100g`.\n",
    "\n",
    "1. **Column-wise missingness**  \n",
    "   - Compute the number of missing values **per column** \n",
    "   - This tells you which nutrients are more often missing across all products.  \n",
    "   <br>\n",
    "   Hints: Use [DataFrame.isna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html), [DataFrame.sum](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\n",
    "\n",
    "2. **Row-wise missingness**  \n",
    "   - Create a new column `nutr_missing_n` = number of missing nutrients **per row**.  \n",
    "   - Use `.isna().sum(axis=1)` to count missing values across columns instead of down rows.  \n",
    "   ```python\n",
    "   df[\"nutr_missing_n\"] = df[nutr4].isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4124e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4.2 ‚Äî Identify missingness for the core nutrients\n",
    "nutr4 = [\"sugars_100g\",\"fat_100g\",\"salt_100g\",\"proteins_100g\"]\n",
    "\n",
    "# Column-wise missing count and ratio\n",
    "col_missing = df[nutr4].isna().sum().to_frame(\"missing_n\")\n",
    "col_missing[\"missing_pct\"] = (col_missing[\"missing_n\"] / len(df)) * 100\n",
    "print(col_missing.sort_values(\"missing_pct\", ascending=False))\n",
    "\n",
    "# Row-wise missingness\n",
    "df[\"nutr_missing_n\"] = df[nutr4].isna().sum(axis=1)\n",
    "df[\"nutr_missing_n\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8176b",
   "metadata": {},
   "source": [
    "### A4.3 ‚Äî Remove missing values (1 XP)\n",
    "Drop rows where all 4 core nutrients are missing.\n",
    "   These rows are not useful for analysis.  \n",
    "\n",
    "   Hint: use [DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "\n",
    "Print how many rows have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4a7e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4.3 ‚Äî Drop rows where ALL 4 core nutrients are missing\n",
    "before = len(df)\n",
    "df = df.dropna(subset=nutr4, how=\"all\").copy()\n",
    "after = len(df)\n",
    "print(f\"Rows removed where all 4 nutrients missing: {before - after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7160c1",
   "metadata": {},
   "source": [
    "### A4.4 ‚Äî Simple imputations (1 XP)\n",
    "\n",
    "Some nutrient values are missing. To prepare a cleaner dataset, we will create **imputed versions** of selected columns while **keeping the originals unchanged**.\n",
    "\n",
    "1. **Fill missing fiber with 0**  \n",
    "   - If the column `fiber_100g` exists, create a new column `fiber_filled` where missing values are replaced with `0`.  \n",
    "   - Hint: use [`Series.fillna`](https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html) on the proper column.\n",
    "\n",
    "2. **Median-impute the 4 core nutrients**  \n",
    "   - For each core nutrient (`sugars_100g`, `fat_100g`, `salt_100g`, `proteins_100g`), create a new column with suffix `_imp`.  \n",
    "   - Compute the **global median** of each column with `.median()`.  \n",
    "   - Replace missing values with that median using `.fillna()`.  \n",
    "\n",
    "   **Example for sugars:**  \n",
    "   ```python\n",
    "   median_sugar = df[\"sugars_100g\"].median()\n",
    "   df[\"sugars_100g_imp\"] = df[\"sugars_100g\"].fillna(median_sugar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e5018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4.4 ‚Äî Simple imputations\n",
    "# Create imputed copies without overwriting originals\n",
    "for c in nutr4:\n",
    "    imp_col = f\"{c}_imp\"\n",
    "    median_val = df[c].median(skipna=True)\n",
    "    df[imp_col] = df[c].fillna(median_val)\n",
    "\n",
    "# If fiber_100g exists, create a zero-imputed version\n",
    "if \"fiber_100g\" in df.columns:\n",
    "    df[\"fiber_100g_imp0\"] = df[\"fiber_100g\"].fillna(0.0)\n",
    "\n",
    "df[[c for c in df.columns if c.endswith(\"_imp\")]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9b621",
   "metadata": {},
   "source": [
    "### A4.5 ‚Äî Convert type for Nutri-Score (1 XP)\n",
    "\n",
    "The column `nutriscore_grade` currently contains letters (`a`‚Äì`e`) as **strings**.  \n",
    "If we keep them as plain strings, sorting/comparisons will just follow alphabetical order, which is not guaranteed to match the intended **nutritional ranking**.\n",
    "\n",
    "We want to convert it to an **ordered categorical** type, so that Pandas understands the correct order:  \n",
    "`a < b < c < d < e`.\n",
    "\n",
    "**Steps to follow:**\n",
    "1. Import `CategoricalDtype` from `pandas.api.types`.  \n",
    "   ```python\n",
    "   from pandas.api.types import CategoricalDtype\n",
    "   ```\n",
    "2.\tDefine the nutritional order:\n",
    "   ```python\n",
    "   nutri_order = CategoricalDtype(\n",
    "      categories=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "      ordered=True\n",
    "   )\n",
    "   ```\n",
    "3. Apply the conversion\n",
    "   Hint: use .astype(nutri_order) on the appropriate column\n",
    "4. Verify (explain how you did it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d616ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4.5 ‚Äî Convert nutriscore_grade to ordered categorical and numeric\n",
    "# Clean string 'nan' to real NaN before conversion\n",
    "df[\"nutriscore_grade\"] = df[\"nutriscore_grade\"].astype(str).str.strip().str.lower().replace(\"nan\", np.nan)\n",
    "\n",
    "# Define ordered category\n",
    "order = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "df[\"nutriscore_grade\"] = pd.Categorical(df[\"nutriscore_grade\"], categories=order, ordered=True)\n",
    "\n",
    "# Map to numbers (a=1 .. e=5) for easier averaging (nullable integer)\n",
    "grade_map = {\"a\":1, \"b\":2, \"c\":3, \"d\":4, \"e\":5}\n",
    "df[\"grade_num\"] = df[\"nutriscore_grade\"].astype(str).map(grade_map).astype(\"Int64\")\n",
    "df[[\"nutriscore_grade\",\"grade_num\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7147b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî A4: Completed types and missing data handling (total=28)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c46e3",
   "metadata": {},
   "source": [
    "## A5. GroupBy & Cross-tabulation (10 XP)\n",
    "\n",
    "Summarize nutrients by high-level food groups and examine grade distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cff0ff",
   "metadata": {},
   "source": [
    "### A5.1 ‚Äî Grouped nutrient summary (5 XP)\n",
    "\n",
    "For each high-level food group (`pnns_groups_1`), compute the **mean** and **standard deviation** of:  \n",
    "`sugars_100g, fat_100g, salt_100g, proteins_100g`.  \n",
    "\n",
    "üí° Hint: use [groupby] and [agg]\n",
    "\n",
    "üìñ Docs: [GroupBy.agg](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.agg.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c317686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5.1 ‚Äî Grouped nutrient summary by pnns_groups_1\n",
    "metrics = {\n",
    "    \"sugars_100g\": \"median\",\n",
    "    \"fat_100g\": \"median\",\n",
    "    \"salt_100g\": \"median\",\n",
    "    \"proteins_100g\": \"median\"\n",
    "}\n",
    "grouped = df.groupby(\"pnns_groups_1\").agg(metrics)\n",
    "grouped = grouped.sort_index()\n",
    "grouped.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ed9ad",
   "metadata": {},
   "source": [
    "### A5.2 ‚Äî Find groups with lowest average sugars (2 XP)\n",
    "\n",
    "Identify the **three food groups** with the **lowest average sugar content** (`sugars_100g`).  \n",
    "\n",
    "üí° Hint: first compute the group means, then apply `.nsmallest(3)`.\n",
    "\n",
    "üìñ Docs: [Series.nsmallest](https://pandas.pydata.org/docs/reference/api/pandas.Series.nsmallest.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cab8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5.2 ‚Äî Groups with lowest average sugars\n",
    "avg_sugar = df.groupby(\"pnns_groups_1\")[\"sugars_100g\"].mean().sort_values()\n",
    "avg_sugar.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c3ba5",
   "metadata": {},
   "source": [
    "### A5.3 Crosstab of Nutri-Score by group (3 XP)\n",
    "\n",
    "Let‚Äôs explore how nutrition **grades** distribute across food groups, as defined by the `pnns_groups_1` column (do not use the previous results from groupby, but work on the original dataframe).\n",
    "\n",
    "**Task**\n",
    "- Build a **crosstab** for counts of `nutriscore_grade` by `pnns_groups_1` for the **top 5 groups** (by count).  \n",
    "\n",
    "üí° **What is a crosstab?**  \n",
    "A *crosstabulation* (or contingency table) shows how two categorical variables are distributed against each other:  \n",
    "- Rows = categories of one variable  \n",
    "- Columns = categories of another variable  \n",
    "- Cells = counts (or other aggregates) of their intersections  \n",
    "\n",
    "**Why is this useful here?**  \n",
    "In our dataset, a crosstab between `pnns_groups_1` (food group) and `nutriscore_grade` (nutrition label a‚Äìe) helps us see **how nutritional quality varies across food groups**.  \n",
    "For example:  \n",
    "- *Beverages* may cluster around `d` or `e`  \n",
    "- *Fruits* may cluster around `a` or `b`  \n",
    "\n",
    "This reveals patterns of nutritional quality across categories at a glance.\n",
    "  \n",
    "üí° Hint: use the pandas `crosstab` function.\n",
    "\n",
    "üìñ [pandas.crosstab](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b06491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5.3 ‚Äî Crosstab of Nutri-Score by group\n",
    "ct = pd.crosstab(df[\"pnns_groups_1\"], df[\"nutriscore_grade\"]).loc[:, [\"a\",\"b\",\"c\",\"d\",\"e\"]]\n",
    "ct.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c201ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+10 XP ‚Äî A5: Completed groupby and crosstab (total=38)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07b79f",
   "metadata": {},
   "source": [
    "# Part B ‚Äî Plots & Interpretation (25 XP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643eb2c",
   "metadata": {},
   "source": [
    "## B1. Distributions (8 XP)\n",
    "\n",
    "Explore sugar distributions overall and across groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff4b74",
   "metadata": {},
   "source": [
    "### B1.1 ‚Äî Histogram of sugars (3 XP)\n",
    "\n",
    "Plot a **histogram** of `sugars_100g` to see how sugar values are distributed across all products.\n",
    "\n",
    "üí° Hints:  \n",
    "- Use [`plt.hist`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html).  \n",
    "- Drop `na` values if still present on `sugar_100g`.\n",
    "- Nutrient data often contains extreme outliers. To avoid a squashed plot, you can clip values above the 99th percentile:  \n",
    "  ```python\n",
    "  cutoff = df[\"sugars_100g\"].quantile(0.99)\n",
    "  data = df[\"sugars_100g\"].clip(upper=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e354e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1.1 ‚Äî Histogram of sugars\n",
    "sug = df[\"sugars_100g\"].dropna()\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(sug, bins=50)\n",
    "plt.xlabel(\"Sugars (g per 100g)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of sugars per 100g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c53a33",
   "metadata": {},
   "source": [
    "### B1.2 ‚Äî Boxplot of sugars by food group (3 XP)\n",
    "\n",
    "Compare sugar content across the **top 5 most frequent food groups** (`pnns_groups_1`).\n",
    "\n",
    "üí° Hints:  \n",
    "1. First, find the top 5 groups with `.value_counts().head(5)`. Consider removing the \"unknown\" group. \n",
    "2. Subset the DataFrame to only those groups.  \n",
    "3. Create a **boxplot** with `plt.boxplot`, grouping values by food group.  \n",
    "   - Set `showfliers=False` to hide extreme outliers for readability.  \n",
    "   - Provide labels for each boxplot (the group names).  \n",
    "4. Rotate x-axis labels if they overlap.  \n",
    "\n",
    "üìñ Docs: [matplotlib.pyplot.boxplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2df23081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1.2 ‚Äî Boxplot of sugars by top groups (exclude Unknown)\n",
    "# Pick top 5 groups by count excluding 'Unknown'\n",
    "grp_counts = df[\"pnns_groups_1\"].value_counts()\n",
    "top5 = [g for g in grp_counts.index if pd.notna(g) and g.lower() != \"unknown\"][:5]\n",
    "\n",
    "subset = df[df[\"pnns_groups_1\"].isin(top5)][[\"pnns_groups_1\",\"sugars_100g\"]].dropna()\n",
    "plt.figure(figsize=(8,5))\n",
    "subset.boxplot(column=\"sugars_100g\", by=\"pnns_groups_1\")\n",
    "plt.title(\"Sugars by group (top 5)\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Group\")\n",
    "plt.ylabel(\"Sugars (g/100g)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3119d",
   "metadata": {},
   "source": [
    "### B1.3 ‚Äî Interpretation (2 XP)\n",
    "Overall sugar distribution is **right-skewed** with many low-to-moderate sugar products and a tail of high-sugar items.  \n",
    "Across groups, **Sugary snacks** and some **Beverages** tend to show higher medians and wider IQRs, while **Milk and dairy products** cluster lower, reflecting naturally lower sugar (or lactose-managed) products. Outliers likely correspond to desserts and sweetened drinks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28dc5c6",
   "metadata": {},
   "source": [
    "Complete:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6717d4f",
   "metadata": {},
   "source": [
    "- Right-skewed sugars: many low‚Äìmoderate items, long high-sugar tail.\n",
    "- Higher median & spread in Sugary snacks and some Beverages; Milk & dairy lower.\n",
    "- Outliers mainly desserts and sweetened drinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1db559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî B1: Completed distribution visualization (total=46)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172665da",
   "metadata": {},
   "source": [
    "## B2 Nutri-Score trends (6 XP)\n",
    "\n",
    "Analyze how **median nutrient values** evolve across **Nutri-Score grades**.\n",
    "\n",
    "1. **Group by Nutri-Score grade**  \n",
    "   - Use the ordered categorical `nutriscore_grade` defined earlier.  \n",
    "   - Compute the **median** of the following columns:  \n",
    "     - `sugars_100g`  \n",
    "     - `fat_100g`  \n",
    "     - `salt_100g`  \n",
    "   - üìñ Docs: [DataFrame.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
    "\n",
    "2. **Plot median values**  \n",
    "   - Create a **single line plot** with one axis.  \n",
    "   - Each nutrient should appear as a separate line, with markers for clarity.  \n",
    "   - Suggested usage:  \n",
    "     ```python\n",
    "     medians.plot(\n",
    "         kind=\"line\",\n",
    "         marker=\"o\"\n",
    "     )\n",
    "     ```  \n",
    "   - üìñ Docs: [DataFrame.plot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)\n",
    "\n",
    "**Hints**\n",
    "- After grouping, use `.median()` to compute medians.  \n",
    "- Ensure the `nutriscore_grade` column is categorical and ordered (A ‚Üí E) to preserve logical axis ordering.  \n",
    "- If grades are out of order, use:  \n",
    "  ```python\n",
    "  df[\"nutriscore_grade\"] = pd.Categorical(\n",
    "      df[\"nutriscore_grade\"],\n",
    "      categories=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "      ordered=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bff27e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2 ‚Äî Nutri-Score trends (median nutrients by grade)\n",
    "# Ensure ordered categories for plotting\n",
    "df[\"nutriscore_grade\"] = pd.Categorical(df[\"nutriscore_grade\"], categories=[\"a\",\"b\",\"c\",\"d\",\"e\"], ordered=True)\n",
    "\n",
    "med = (df.groupby(\"nutriscore_grade\")[[\"sugars_100g\",\"fat_100g\",\"salt_100g\"]]\n",
    "         .median())\n",
    "\n",
    "# Line plot with markers for 3 nutrients\n",
    "plt.figure(figsize=(8,5))\n",
    "for col in med.columns:\n",
    "    plt.plot(med.index.astype(str), med[col], marker=\"o\", label=col)\n",
    "plt.xlabel(\"Nutri-Score grade (a=best ‚Üí e=worst)\")\n",
    "plt.ylabel(\"Median value (per 100g)\")\n",
    "plt.title(\"Median nutrients across Nutri-Score grades\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b388ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî B2: Completed Nutri-Score Trends (total=54)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2c7ed",
   "metadata": {},
   "source": [
    "## B3. Scatter + rule-based flag (10 XP)\n",
    "\n",
    "Examine the sugar‚Äìprotein relationship and flag suspicious items.\n",
    "\n",
    "**Tasks**\n",
    "1. Make a **scatter plot** of `sugars_100g` (x) vs `proteins_100g` (y). Use small markers and some alpha for readability.\n",
    "   - Docs: [matplotlib.pyplot.scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html)\n",
    "2. Create a boolean column `is_suspicious` defined by: `sugars_100g > 30` **and** `proteins_100g < 3`.\n",
    "3. Show a table of the **top 5 suspicious products** with columns: `product_name, brands, pnns_groups_1, sugars_100g, proteins_100g` (sorted by high sugar then low protein).\n",
    "\n",
    "**Goal**: mix visualization with simple logic to find extreme items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eeb0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3 ‚Äî Scatter and suspicious flag\n",
    "x = df[\"sugars_100g\"]\n",
    "y = df[\"proteins_100g\"]\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(x, y, s=12, alpha=0.4)\n",
    "plt.xlabel(\"Sugars (g/100g)\")\n",
    "plt.ylabel(\"Proteins (g/100g)\")\n",
    "plt.title(\"Sugars vs Proteins\")\n",
    "plt.show()\n",
    "\n",
    "df[\"is_suspicious\"] = (df[\"sugars_100g\"] > 30) & (df[\"proteins_100g\"] < 3)\n",
    "\n",
    "susp = df[df[\"is_suspicious\"]].copy()\n",
    "cols = [\"product_name\",\"brands\",\"pnns_groups_1\",\"sugars_100g\",\"proteins_100g\"]\n",
    "susp = susp.sort_values(by=[\"sugars_100g\",\"proteins_100g\"], ascending=[False, True])\n",
    "susp[cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e4b5362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+10 XP ‚Äî B3: Scatter plots and rule-based flags. (total=64)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442b82a",
   "metadata": {},
   "source": [
    "# Part C (Extra): Brands & Categories (15 XP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2a0bb",
   "metadata": {},
   "source": [
    "## C1. Brand averages (8 XP)\n",
    "\n",
    "Compare **brands** by their **average Nutri-Score**.\n",
    "\n",
    "1. **Prepare `brand_main`**  \n",
    "   - Ensure you have a column `brand_main` (first brand, lowercased).  \n",
    "   - You should already have it from **A3**. If not, create it as:  \n",
    "     ```python\n",
    "     df[\"brand_main\"] = (\n",
    "         df[\"brands\"]\n",
    "         .str.split(\",\")\n",
    "         .str[0]\n",
    "         .str.strip()\n",
    "         .str.lower()\n",
    "     )\n",
    "     ```\n",
    "\n",
    "2. **Numeric Nutri-Score mapping**  \n",
    "   - Map grades to integers:  \n",
    "     - `a ‚Üí 0, b ‚Üí 1, c ‚Üí 2, d ‚Üí 3, e ‚Üí 4`  \n",
    "   - Store the result in a new column `grade_num` with integer dtype.  \n",
    "   - Handle **missing values** properly:  \n",
    "     - Some entries may be `NaN` (actual missing values).  \n",
    "     - Others may be the string `\"nan\"` ‚Äî convert these to `NaN`.  \n",
    "     - Remove rows with missing `brand_main` or `grade_num` before analysis.  \n",
    "   - üìñ Docs: [Series.map](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html), [DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "\n",
    "3. **Aggregate and visualize**  \n",
    "   - Identify the **top 10 brands** by frequency:  \n",
    "     ```python\n",
    "     top_brands = df[\"brand_main\"].value_counts().head(10).index\n",
    "     ```  \n",
    "   - Filter the dataset to keep only these brands.  \n",
    "   - Compute the **mean `grade_num`** for each brand.  \n",
    "   - Sort results ascending (best brands first).  \n",
    "   - Plot as a **bar chart**.  \n",
    "   - üìñ Docs:  \n",
    "     - [Series.value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)  \n",
    "     - [DataFrame.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)  \n",
    "     - [DataFrame.plot.bar](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)  \n",
    "\n",
    "**Hints**\n",
    "- Use `replace(\"nan\", np.nan)` before dropping NAs to catch string `\"nan\"`.  \n",
    "- Use `df[\"grade_num\"].astype(\"Int64\")` for a nullable integer column.  \n",
    "- Sorting ascending gives a **leaderboard** where **lower = healthier**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f97bea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 ‚Äî Brand averages (mean grade_num among top brands)\n",
    "# Ensure brand_main exists\n",
    "if \"brand_main\" not in df.columns:\n",
    "    df[\"brand_main\"] = (\n",
    "        df[\"brands\"].str.split(\",\").str[0].str.strip().str.lower()\n",
    "    )\n",
    "\n",
    "# Clean and ensure grade_num is available\n",
    "df[\"nutriscore_grade\"] = df[\"nutriscore_grade\"].astype(str).str.strip().str.lower().replace(\"nan\", np.nan)\n",
    "order = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "df[\"nutriscore_grade\"] = pd.Categorical(df[\"nutriscore_grade\"], categories=order, ordered=True)\n",
    "grade_map = {\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5}\n",
    "df[\"grade_num\"] = df[\"nutriscore_grade\"].astype(str).map(grade_map).astype(\"Int64\")\n",
    "\n",
    "# Keep only top 10 brands by count\n",
    "top_brands = df[\"brand_main\"].value_counts().head(10).index\n",
    "df_topb = df[df[\"brand_main\"].isin(top_brands)].copy()\n",
    "\n",
    "brand_avg = df_topb.groupby(\"brand_main\")[\"grade_num\"].mean().sort_values()\n",
    "print(brand_avg)\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(8,4))\n",
    "brand_avg.plot(kind=\"bar\")\n",
    "plt.ylabel(\"Mean grade (lower=better)\")\n",
    "plt.title(\"Top 10 brands by count: average Nutri-Score (1=a ‚Ä¶ 5=e)\")\n",
    "plt.show()\n",
    "\n",
    "brand_avg.to_frame(\"mean_grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0093b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî C1: Completed Brand averages. (total=72)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224abfbb",
   "metadata": {},
   "source": [
    "## C2. Category leaderboard (8 XP)\n",
    "\n",
    "Build a compact table for the top groups.\n",
    "\n",
    "1. Take the **top 5** `pnns_groups_1` by count.\n",
    "2. For those groups, compute: **count**, **mean sugars**, **mean salt**, and **% of grades in {a,b}**.\n",
    "   - `% of {a,b}` can be computed using a boolean mask and `groupby(...).mean()*100`.\n",
    "3. Show the resulting table sorted by `count` descending.\n",
    "\n",
    "**Goal**: create a small multi-metric leaderboard per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ff24b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2 ‚Äî Category leaderboard\n",
    "top5_groups = df[\"pnns_groups_1\"].value_counts().head(5).index\n",
    "dff = df[df[\"pnns_groups_1\"].isin(top5_groups)].copy()\n",
    "\n",
    "agg_tbl = dff.groupby(\"pnns_groups_1\").agg(\n",
    "    count=(\"pnns_groups_1\",\"size\"),\n",
    "    mean_sugars=(\"sugars_100g\",\"mean\"),\n",
    "    mean_salt=(\"salt_100g\",\"mean\")\n",
    ")\n",
    "\n",
    "# % of {a,b}\n",
    "good_mask = dff[\"nutriscore_grade\"].isin([\"a\",\"b\"])\n",
    "pct_good = (dff.assign(good=good_mask)\n",
    "              .groupby(\"pnns_groups_1\")[\"good\"].mean()*100.0)\n",
    "\n",
    "leader = agg_tbl.join(pct_good.rename(\"%_ab\")).sort_values(\"count\", ascending=False)\n",
    "leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6325d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+8 XP ‚Äî C2: Categoryy leaderboard. (total=80)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb66646",
   "metadata": {},
   "source": [
    "## Part D ‚Äî PCA (optional, 20 XP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2ed88",
   "metadata": {},
   "source": [
    "### D1. PCA on nutrient features (20 XP)\n",
    "\n",
    "Apply **Principal Component Analysis (PCA)** to reduce nutrient dimensions and interpret the main components.\n",
    "\n",
    "1. **Select features**  \n",
    "   - Nutrients: `sugars_100g`, `fat_100g`, `salt_100g`, `proteins_100g`, `energy-kcal_100g`, `fiber_100g`  \n",
    "   - Drop rows with missing values before building the feature matrix.\n",
    "\n",
    "2. **Standardize**  \n",
    "   - Use `StandardScaler` to center and scale features.  \n",
    "   - Standardization is important because nutrients are in different units (g, kcal, etc.).  \n",
    "   - üìñ [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "3. **Fit PCA**  \n",
    "   - Run `PCA()` on the standardized data.  \n",
    "   - Plot both the explained variance ratio (per component) and the cumulative ratio.  \n",
    "   - These show how much information each principal component captures.  \n",
    "   - üìñ [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "4. **Loadings & PC1**  \n",
    "   - Loadings indicate how strongly each feature contributes to a component.  \n",
    "   - Identify the feature with the **largest absolute loading** in PC1 (the main driver of dietary variation).\n",
    "\n",
    "5. **Correlation circle (PC1‚ÄìPC2)**  \n",
    "   - Draw a unit circle.  \n",
    "   - Plot arrows from (0,0) to each feature‚Äôs coordinates on the first two PCs.  \n",
    "   - Use loadings + eigenvalues from PCA to compute coordinates.  \n",
    "   - Annotate arrows with variable names for clarity.\n",
    "\n",
    "**Hints**\n",
    "- Check `pca.explained_variance_ratio_` for variance plots.  \n",
    "- Use `pca.components_.T` to access loadings.  \n",
    "- A variable pointing near the PC1 or PC2 axis is strongly correlated with that component.  \n",
    "- Opposite directions suggest negative correlation between nutrients.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1 ‚Äî PCA on nutrient features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1) Select features\n",
    "features = [c for c in [\"sugars_100g\",\"fat_100g\",\"salt_100g\",\"proteins_100g\",\"energy-kcal_100g\",\"fiber_100g\"] if c in df.columns]\n",
    "X = df[features].dropna().copy()\n",
    "\n",
    "# 2) Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3) PCA\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "expl = pca.explained_variance_ratio_\n",
    "print(\"Explained variance ratio (PC1, PC2):\", expl)\n",
    "\n",
    "# 4) Loadings\n",
    "loadings = pd.DataFrame(pca.components_.T, index=features, columns=[\"PC1\",\"PC2\"])\n",
    "print(\"\\nPCA loadings:\")\n",
    "print(loadings)\n",
    "\n",
    "# Main driver (highest |loading| on PC1)\n",
    "main_driver = loadings[\"PC1\"].abs().sort_values(ascending=False).index[0]\n",
    "print(\"\\nMain driver of PC1:\", main_driver)\n",
    "\n",
    "# 5) Correlation circle (PC1‚ÄìPC2)\n",
    "theta = np.linspace(0, 2*np.pi, 200)\n",
    "circle_x = np.cos(theta)\n",
    "circle_y = np.sin(theta)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(circle_x, circle_y)\n",
    "plt.axhline(0); plt.axvline(0)\n",
    "for var in features:\n",
    "    x,y = loadings.loc[var, \"PC1\"], loadings.loc[var, \"PC2\"]\n",
    "    plt.arrow(0,0,x,y, head_width=0.03, length_includes_head=True)\n",
    "    plt.text(x*1.05, y*1.05, var, ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Correlation circle (PC1‚ÄìPC2)\")\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.show()\n",
    "\n",
    "# Also return the PCA coordinates for reference\n",
    "pca_df = pd.DataFrame(X_pca, columns=[\"PC1\",\"PC2\"]).join(X.reset_index(drop=True))\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61299f",
   "metadata": {},
   "source": [
    "**Interpretation (D1).**  \n",
    "PC1 typically contrasts **energy-dense, salty/fatty** items against **leaner / lower-salt** ones (high positive loadings on energy/fat/salt).  \n",
    "PC2 often loads on **sugars vs proteins/fiber**, separating **sweet** foods from **protein-/fiber-richer** items. Exact directions follow the loadings table printed above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baebd8c",
   "metadata": {},
   "source": [
    "- PC1: energy/fat/salt-dense ‚Üî lean/low-salt (largest |loadings| on energy, fat, salt).\n",
    "- PC2: sugars ‚Üî proteins/fiber (sweet vs protein/fiber-rich foods).\n",
    "- Driver check: confirm with the loadings table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8529a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+20 XP ‚Äî D: PCA completed. (total=100)\n"
     ]
    }
   ],
   "source": [
    "# Do not modify anything in this cell.\n",
    "# Each task is worth a certain number of points.\n",
    "# We call the award function with the appropriate number of points when you complete each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb892f",
   "metadata": {},
   "source": [
    "## Wrap-up & grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62026c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XP=100 ‚Üí Grade=20/20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
